{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastAPI NLP API Demo\n",
    "\n",
    "This notebook demonstrates how to interact with the NLP API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import websocket\n",
    "import threading\n",
    "from IPython.display import display, HTML, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API configuration\n",
    "BASE_URL = \"http://localhost:8000/api/v1\"\n",
    "# Default credentials (update these)\n",
    "USERNAME = \"admin\"\n",
    "PASSWORD = \"password\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Authentication\n",
    "\n",
    "First, let's authenticate with the API to get a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(username, password):\n",
    "    \"\"\"Get authentication token from the API.\"\"\"\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/token\",\n",
    "        data={\"username\": username, \"password\": password},\n",
    "        headers={\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        token_data = response.json()\n",
    "        return token_data[\"access_token\"]\n",
    "    else:\n",
    "        print(f\"Authentication failed with status code {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the authentication token\n",
    "token = get_token(USERNAME, PASSWORD)\n",
    "\n",
    "if token:\n",
    "    print(f\"Authentication successful! Token obtained.\")\n",
    "    # Set up the default headers with our token\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "else:\n",
    "    print(\"Failed to get token. Please check your credentials.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Health Check\n",
    "\n",
    "Let's check if the API is healthy and all models are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_health():\n",
    "    \"\"\"Check the health status of the API.\"\"\"\n",
    "    response = requests.get(f\"{BASE_URL}/health\")\n",
    "    return response.json()\n",
    "\n",
    "health_status = check_health()\n",
    "display(JSON(health_status))\n",
    "\n",
    "# Visual representation of model availability\n",
    "if \"models\" in health_status:\n",
    "    models_df = pd.DataFrame([{\"model\": k, \"available\": v} for k, v in health_status[\"models\"].items()])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=\"model\", y=\"available\", data=models_df)\n",
    "    plt.title(\"Model Availability\")\n",
    "    plt.ylabel(\"Available\")\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get User Information\n",
    "\n",
    "Let's check the current user's information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_info():\n",
    "    \"\"\"Get current user information.\"\"\"\n",
    "    response = requests.get(\n",
    "        f\"{BASE_URL}/users/me\",\n",
    "        headers=headers\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "user_info = get_user_info()\n",
    "display(JSON(user_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "\n",
    "Let's analyze the sentiment of some example texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text, language=\"en\"):\n",
    "    \"\"\"Analyze the sentiment of the given text.\"\"\"\n",
    "    payload = {\n",
    "        \"text\": text,\n",
    "        \"language\": language\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/sentiment\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "    \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with some example texts\n",
    "example_texts = [\n",
    "    \"I love this product, it's amazing!\",\n",
    "    \"This is the worst experience ever.\",\n",
    "    \"The package arrived on time.\",\n",
    "    \"I'm not sure what to think about this.\"\n",
    "]\n",
    "\n",
    "sentiment_results = []\n",
    "for text in example_texts:\n",
    "    result = analyze_sentiment(text)\n",
    "    sentiment_results.append(result)\n",
    "    display(JSON(result))\n",
    "    \n",
    "# Create a visualization of the sentiment scores\n",
    "sentiment_df = pd.DataFrame([\n",
    "    {\"text\": r[\"text\"], \"sentiment\": r[\"sentiment\"], \"score\": r[\"score\"]} \n",
    "    for r in sentiment_results\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = sns.barplot(x=\"text\", y=\"score\", hue=\"sentiment\", data=sentiment_df)\n",
    "plt.title(\"Sentiment Analysis Results\")\n",
    "plt.ylabel(\"Confidence Score\")\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Named Entity Recognition\n",
    "\n",
    "Let's extract entities from some sample texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    \"\"\"Extract named entities from the given text.\"\"\"\n",
    "    payload = {\"text\": text}\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/entities\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "    \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_text = \"Apple is looking to buy U.K. startup for $1 billion in January 2023. Microsoft CEO Satya Nadella announced the news in New York.\"\n",
    "entities = extract_entities(ner_text)\n",
    "display(JSON(entities))\n",
    "\n",
    "# Create a visualization of entity types\n",
    "if entities and \"entities\" in entities:\n",
    "    entities_df = pd.DataFrame(entities[\"entities\"])\n",
    "    \n",
    "    # Count entities by type\n",
    "    entity_counts = entities_df[\"type\"].value_counts().reset_index()\n",
    "    entity_counts.columns = [\"entity_type\", \"count\"]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=\"entity_type\", y=\"count\", data=entity_counts)\n",
    "    plt.title(\"Entity Types in Text\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlabel(\"Entity Type\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display the annotated text\n",
    "    def highlight_entities(text, entities):\n",
    "        \"\"\"Highlight entities in text with HTML colors.\"\"\"\n",
    "        colors = {\n",
    "            \"PERSON\": \"#FF9999\",\n",
    "            \"ORG\": \"#99FF99\",\n",
    "            \"LOC\": \"#9999FF\",\n",
    "            \"DATE\": \"#FFFF99\",\n",
    "            \"TIME\": \"#99FFFF\",\n",
    "            \"MONEY\": \"#FF99FF\",\n",
    "            \"PERCENT\": \"#FFCC99\",\n",
    "        }\n",
    "        \n",
    "        # Sort entities by start position (reversed to avoid index issues)\n",
    "        sorted_entities = sorted(entities, key=lambda x: x[\"start\"], reverse=True)\n",
    "        \n",
    "        result = text\n",
    "        for entity in sorted_entities:\n",
    "            start = entity[\"start\"]\n",
    "            end = entity[\"end\"]\n",
    "            entity_type = entity[\"type\"]\n",
    "            entity_text = text[start:end]\n",
    "            color = colors.get(entity_type, \"#CCCCCC\")\n",
    "            \n",
    "            highlight = f'<span style=\"background-color: {color}; padding: 2px; border-radius: 3px;\" title=\"{entity_type}\">{entity_text}</span>'\n",
    "            result = result[:start] + highlight + result[end:]\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    highlighted_text = highlight_entities(entities[\"text\"], entities[\"entities\"])\n",
    "    display(HTML(f\"<p style='font-size: 16px; line-height: 1.5;'>{highlighted_text}</p>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Entity Filtering\n",
    "\n",
    "Let's try filtering entities by type and confidence score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_entities(text, entity_types=None, min_score=0.5):\n",
    "    \"\"\"Filter entities by type and minimum confidence score.\"\"\"\n",
    "    params = {\"text\": text, \"min_score\": min_score}\n",
    "    \n",
    "    if entity_types:\n",
    "        params[\"entity_types\"] = entity_types\n",
    "    \n",
    "    response = requests.get(\n",
    "        f\"{BASE_URL}/entities/filter\",\n",
    "        headers=headers,\n",
    "        params=params\n",
    "    )\n",
    "    \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only for organizations and persons with high confidence\n",
    "filtered_entities = filter_entities(\n",
    "    ner_text, \n",
    "    entity_types=[\"ORG\", \"PERSON\"], \n",
    "    min_score=0.7\n",
    ")\n",
    "\n",
    "display(JSON(filtered_entities))\n",
    "\n",
    "# Compare filtered vs total entities count\n",
    "if \"filtered_from\" in filtered_entities and \"filtered_to\" in filtered_entities:\n",
    "    filter_stats = pd.DataFrame([\n",
    "        {\"category\": \"Total Entities\", \"count\": filtered_entities[\"filtered_from\"]},\n",
    "        {\"category\": \"Filtered Entities\", \"count\": filtered_entities[\"filtered_to\"]}\n",
    "    ])\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x=\"category\", y=\"count\", data=filter_stats)\n",
    "    plt.title(\"Entity Filtering Results\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Text Classification\n",
    "\n",
    "Let's classify some sample texts into categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text, labels, multi_label=False):\n",
    "    \"\"\"Classify text into given categories.\"\"\"\n",
    "    payload = {\n",
    "        \"text\": text,\n",
    "        \"labels\": labels,\n",
    "        \"multi_label\": multi_label\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/classify\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "    \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classification presets\n",
    "def get_classification_preset(preset_name):\n",
    "    \"\"\"Get predefined label sets for classification.\"\"\"\n",
    "    response = requests.get(\n",
    "        f\"{BASE_URL}/classify/presets/{preset_name}\",\n",
    "        headers=headers\n",
    "    )\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "# Get the topics preset\n",
    "topics_preset = get_classification_preset(\"topics\")\n",
    "display(JSON(topics_preset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example texts for classification\n",
    "classification_examples = [\n",
    "    \"Climate change poses serious environmental challenges\",\n",
    "    \"The latest smartphone features a 108MP camera and advanced AI\",\n",
    "    \"The stock market plunged 500 points due to economic concerns\",\n",
    "    \"The team won the championship with a last-minute goal\"\n",
    "]\n",
    "\n",
    "# Use the topics from the preset\n",
    "topic_labels = topics_preset[\"labels\"]\n",
    "\n",
    "# Classify each example text\n",
    "classification_results = []\n",
    "for text in classification_examples:\n",
    "    result = classify_text(text, topic_labels)\n",
    "    classification_results.append(result)\n",
    "    display(JSON(result))\n",
    "    \n",
    "# Visualize top categories for each text\n",
    "classification_data = []\n",
    "for result in classification_results:\n",
    "    # Sort labels by score (highest first) and get top label\n",
    "    top_label = sorted(result[\"labels\"], key=lambda x: x.get(\"score\", 0), reverse=True)[0]\n",
    "    classification_data.append({\n",
    "        \"text\": result[\"text\"][:30] + \"...\",  # Truncate long texts\n",
    "        \"top_category\": top_label.get(\"label\"),\n",
    "        \"score\": top_label.get(\"score\")\n",
    "    })\n",
    "\n",
    "class_df = pd.DataFrame(classification_data)\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = sns.barplot(x=\"text\", y=\"score\", hue=\"top_category\", data=class_df)\n",
    "plt.title(\"Top Categories for Example Texts\")\n",
    "plt.ylabel(\"Confidence Score\")\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.legend(title=\"Category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Custom Classification with Query Parameters\n",
    "\n",
    "Let's try the custom classification endpoint that uses query parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_classify(text, labels):\n",
    "    \"\"\"Classify text using query parameters.\"\"\"\n",
    "    params = {\n",
    "        \"text\": text,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/classify/custom\",\n",
    "        headers=headers,\n",
    "        params=params\n",
    "    )\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "# Try with intent classification\n",
    "intent_result = custom_classify(\n",
    "    \"How do I reset my password?\", \n",
    "    [\"question\", \"complaint\", \"feedback\", \"request\"]\n",
    ")\n",
    "display(JSON(intent_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. WebSocket Connection\n",
    "\n",
    "Let's demonstrate the WebSocket API for real-time NLP processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPWebSocketClient:\n",
    "    def __init__(self, url=\"ws://localhost:8000/api/v1/ws\"):\n",
    "        self.url = url\n",
    "        self.ws = None\n",
    "        self.messages = []\n",
    "        self.connected = False\n",
    "    \n",
    "    def on_message(self, ws, message):\n",
    "        \"\"\"Callback when a message is received.\"\"\"\n",
    "        data = json.loads(message)\n",
    "        self.messages.append(data)\n",
    "        print(f\"Received: {json.dumps(data, indent=2)}\")\n",
    "    \n",
    "    def on_error(self, ws, error):\n",
    "        \"\"\"Callback for errors.\"\"\"\n",
    "        print(f\"Error: {error}\")\n",
    "    \n",
    "    def on_close(self, ws, close_status_code, close_msg):\n",
    "        \"\"\"Callback when connection is closed.\"\"\"\n",
    "        print(\"Connection closed\")\n",
    "        self.connected = False\n",
    "    \n",
    "    def on_open(self, ws):\n",
    "        \"\"\"Callback when connection is established.\"\"\"\n",
    "        print(\"Connection opened\")\n",
    "        self.connected = True\n",
    "    \n",
    "    def connect(self):\n",
    "        \"\"\"Connect to the WebSocket.\"\"\"\n",
    "        self.ws = websocket.WebSocketApp(\n",
    "            self.url,\n",
    "            on_open=self.on_open,\n",
    "            on_message=self.on_message,\n",
    "            on_error=self.on_error,\n",
    "            on_close=self.on_close\n",
    "        )\n",
    "        \n",
    "        # Start WebSocket in a background thread\n",
    "        self.thread = threading.Thread(target=self.ws.run_forever)\n",
    "        self.thread.daemon = True\n",
    "        self.thread.start()\n",
    "        \n",
    "        # Wait for connection\n",
    "        time.sleep(1)\n",
    "        return self.connected\n",
    "    \n",
    "    def send(self, data):\n",
    "        \"\"\"Send data to the WebSocket.\"\"\"\n",
    "        if not self.ws or not self.connected:\n",
    "            print(\"Not connected\")\n",
    "            return False\n",
    "        \n",
    "        self.ws.send(json.dumps(data))\n",
    "        return True\n",
    "    \n",
    "    def disconnect(self):\n",
    "        \"\"\"Disconnect from the WebSocket.\"\"\"\n",
    "        if self.ws:\n",
    "            self.ws.close()\n",
    "        \n",
    "        # Wait for thread to finish\n",
    "        if hasattr(self, 'thread') and self.thread.is_alive():\n",
    "            self.thread.join(timeout=1)\n",
    "            \n",
    "        self.connected = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and connect the WebSocket client\n",
    "ws_client = NLPWebSocketClient()\n",
    "connected = ws_client.connect()\n",
    "\n",
    "if connected:\n",
    "    # Try sentiment analysis\n",
    "    ws_client.send({\"action\": \"sentiment\", \"text\": \"I'm really enjoying this API!\"})\n",
    "    time.sleep(1)  # Wait for response\n",
    "    \n",
    "    # Try entity recognition\n",
    "    ws_client.send({\"action\": \"entities\", \"text\": \"Google's headquarters are in Mountain View, California.\"})\n",
    "    time.sleep(1)  # Wait for response\n",
    "    \n",
    "    # Try classification\n",
    "    ws_client.send({\n",
    "        \"action\": \"classify\", \n",
    "        \"text\": \"This computer keeps crashing whenever I open the browser\", \n",
    "        \"labels\": [\"technical issue\", \"feedback\", \"question\"]\n",
    "    })\n",
    "    time.sleep(1)  # Wait for response\n",
    "    \n",
    "    # Wait a bit to receive all responses then disconnect\n",
    "    time.sleep(2)\n",
    "    ws_client.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Admin Actions\n",
    "\n",
    "Let's try using the admin-only endpoint to reload models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_models():\n",
    "    \"\"\"Reload NLP models (admin only).\"\"\"\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/admin/reload-models\",\n",
    "        headers=headers\n",
    "    )\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "reload_result = reload_models()\n",
    "display(JSON(reload_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how to interact with all the major endpoints of the NLP API. You can use this as a starting point to build applications that leverage these natural language processing capabilities.\n",
    "\n",
    "Here's a summary of what we've explored:\n",
    "\n",
    "1. Authentication and getting tokens\n",
    "2. API health checks\n",
    "3. Sentiment analysis\n",
    "4. Named entity recognition\n",
    "5. Text classification\n",
    "6. WebSocket connections for real-time processing\n",
    "7. Admin actions for system management\n",
    "\n",
    "These building blocks can be combined to create powerful NLP-based applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-pipeline-46rPltzW-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
